{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba 1: Análisis de Sentimientos de Twitter\n",
    "\n",
    "<br>\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Nombre del Grupo:</b> Tusca.\n",
    "\n",
    "<b>Integrante 1:</b> Juan Jose Uribe Mella.\n",
    "\n",
    "<b>Integrante 2:</b> Nicolás Ignacio Gómez Espejo.\n",
    "\n",
    "<b>Integrante 3:</b> Rafael Ignacio Mascayano O'Ryan.\n",
    "\n",
    "<b>Integrante 4:</b> Javier Ignacio López Sanhueza.\n",
    "\n",
    "               \n",
    "\n",
    "<b>Generación:</b> Generación 2.\n",
    "\n",
    "<b>Profesor:</b> Gabriel Tamayo L.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A  continuación  se  presenta un  problema clásico en  el  análisis de  texto: Extraer el  sentimiento asociado a un texto. Para esto, utilizaremos una base de datos provenientes de CrowdFlower. Para descargar los datos puede ejecutar el siguiente código: \n",
    "\n",
    "`wget https://www.crowdflower.com/wp-content/uploads/2016/07/text_emotion.csv`\n",
    "\n",
    "El objetivo general de esta prueba es alcanzar el mejor desempeño posible para clasificar si un tweet es positivo o negativo. Para medir el desempeño, se evaluará con un conjunto de datos del cuál no tendrán acceso. De esta manera evitaremos que los modelos aprendan información sobre el conjunto de validación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requerimientos\n",
    "\n",
    "Realizaremos un análisis de sentimientos de un Tweet para saber si este está asociado a un sentimiento positivo o a un sentimiento negativo.\n",
    "\n",
    "![Example](tweet-example.png)\n",
    "\n",
    "Para esto utilizaremos la base de datos provenientes de _CrowdFlower_.\n",
    "\n",
    "## Vector Objetivo\n",
    "\n",
    "El vector objetivo será una variable binaria que indicará si el sentimiento es positivo o no.\n",
    "\n",
    "## Métricas a utilizar\n",
    "\n",
    "Como este es un problema de clasificación, nos centraremos en la predicción de la clasificación para una nueva observación. Para lo cual se utilizarán las siguientes métricas:\n",
    "\n",
    "- **Matrix de confusión**: cantidad de observaciones predichas de forma correcta.\n",
    "- **Accuracy** (exactitud): porcentaje de casos predichos correctamente por sobre el total de casos.\n",
    "- **Precision**: mide la fracción de predicciones correctas entre las etiquetas positivas.\n",
    "- **Recall**: Mide la fraccion de verdaderos positivos predichos por el modelo.\n",
    "- **F1**: representa la media armónica entre Precision y Recall (es decir, una medida general de la presición).\n",
    "- **ROC** (en particular, _AUC_): evalúa la relación entre ambos errores (falsos positivos y falso negativo) condicional en todo el rango del clasificador.\n",
    "\n",
    "De la misma forma se usarán modelos de clasificación entre los que destaca:\n",
    "- Regresión Logística,\n",
    "- Máquina de Soporte Vectorial,\n",
    "- Naive Bernoulli,\n",
    "- Random Forest,\n",
    "- Ridge,\n",
    "- AdaBoost,\n",
    "- Redes Neuronales,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis Exploratorio\n",
    "\n",
    "Se procede a evaluar las variables y explorar de forma grafica el comportamientos de aquellas. Previo a aquello se procede a cargar las librerias necesarias y básicas de un data scientist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'helpers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-68fa14fa2983>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Import helpers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhelpers\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnicos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"darkgrid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'helpers'"
     ]
    }
   ],
   "source": [
    "# Importar librerías básicas\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importación de librerías clásicas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "import missingno as msgo\n",
    "\n",
    "# Importación de librerías de ML\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Importación de librerías para el tratamiento de texto\n",
    "import nltk\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "# Importación de librería para la persistencia del modelo  \n",
    "import pickle\n",
    "\n",
    "# Import helpers\n",
    "import helpers as nicos\n",
    "\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se carga el la base de datos entregada en la web Desafio Latam. \n",
    "# Se observa que es necesario eliminar la columna con \"Unnamed: 0\", debido a que no entrega información\n",
    "\n",
    "df = pd.read_csv('training_tweets.csv').drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Se evalua el contenido y el tipo de dato en su interior. De forma paralela se busca la existencia de NaN.\n",
    "df.info()\n",
    "\n",
    "msgo.matrix(df)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar que el dataset no contiene valores NaN. \n",
    "\n",
    "### Vector Objetivo\n",
    "\n",
    "Veamos como distribuye el vector objetivo sin preprocesar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.countplot(df.sentiment, order=df.sentiment.value_counts().index);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar que hay muchos datos neutrales. Para no afectar el resultado, en la etapa de _feature engineering_ vamos a eliminar los registros neutrales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atributos\n",
    "\n",
    "El único atributo es `content` el cual es el texto con el Tweet. A continuación veremos cuales son las palabras más repetidas considerando todas las observaciones no neutrales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nicos.most_common_words(df[df.sentiment != 'neutral'].content.str.lower())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las palabras asociadas a sentimientos positivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nicos.most_common_words(df[df.sentiment.isin(['happiness', 'love', 'surprise', 'fun', 'relief', 'enthusiasm'])].content.str.lower())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las palabras asociadas a sentimientos negativos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nicos.most_common_words(df[~df.sentiment.isin(['happiness', 'love', 'surprise', 'fun', 'relief', 'enthusiasm'])].content.str.lower())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento y Feature Engineering\n",
    "\n",
    "### Estrategia de Preprocesamiento\n",
    "\n",
    "Se propone realizar un preprocesamiento de los datos, por medio de lo sugerido en el enunciado con Lemantización. Para esto se debe estudiar las funciones de la librería NTLK. De la misma forma, se puede proceder a separar las palabras de los comentarios con CountVectorizer o con TfidVectorizer. \n",
    "Luego de este preprocesamiento, se aplicaran los modelos, evaluando cual de ellos es el mejor, de las misma forma se planea utilziar un modelo de votación de ensamble para evaluar los mejores. De esta forma, se utilizarán los modelos con ambos preprocesamientos, y se eligirá el mejor modelo en tiempo de procesamiento y resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero filtramos sentimientos que no son neutrales\n",
    "df = df[df.sentiment != 'neutral']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora generamos el vector objetivo binarizado\n",
    "positive_elements = ['happiness', 'love', 'surprise', 'fun', 'relief', 'enthusiasm']\n",
    "y = np.where(np.isin(df.sentiment, positive_elements), 1, 0)\n",
    "\n",
    "sns.countplot(y);\n",
    "plt.title('Distribución de Vector Objetivo (positivo = 1)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambas clases están balanceadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicaremos lemantización y tokenización sobre los Tweets.\n",
    "\n",
    "Guardamos en `X` la matriz de atributos (para este ejercicio, es sólo 1 columna):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el preprocesamiento, utilizaremos las stopwords del diccionario inglés junto a otros signos que no aportan información en la clasificación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words(\"english\") + ['!','.','@',',','...','?','s', '&','/',';','-','..','\"', '½']\n",
    "stopwords = set(stopwords)\n",
    "tokenizer = nicos.LemmaTokenizer()\n",
    "tokenized_stopwords = tokenizer(' '.join(stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crearemos un objeto con `CountVectorizer` para utilizarlo en los modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(tokenizer=nicos.LemmaTokenizer(),\n",
    "                                   strip_accents = 'unicode',\n",
    "                                   stop_words = tokenized_stopwords,\n",
    "                                   max_features= 2000,\n",
    "                                   lowercase = True)\n",
    "\n",
    "count_model_fit = count_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las siguientes son las 10 palabras más repetidas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common = pd.DataFrame(count_model_fit.toarray(), columns = count_vectorizer.get_feature_names())\n",
    "most_common = most_common.sum().sort_values(ascending=False)\n",
    "most_common[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, = train_test_split(X, y, test_size = 0.33, random_state = 4092019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primer Modelo: NaiveBernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pip_bernoulli = Pipeline([('countV', count_vectorizer),('NB',BernoulliNB())])\n",
    "model_pip_bernoulli.fit(x_train, y_train)\n",
    "print(classification_report(y_test,model_pip_bernoulli.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segundo Modelo: Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pip_LR = Pipeline([('countV', count_vectorizer),('Lg', LogisticRegression(random_state=4092019))])\n",
    "model_pip_LR.fit(x_train, y_train)\n",
    "print(classification_report(y_test,model_pip_LR.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "tfid = TfidfVectorizer(tokenizer=nltk.tokenize.TweetTokenizer().tokenize,\n",
    "                                   strip_accents = 'unicode',\n",
    "                                   stop_words = nltk.tokenize.TweetTokenizer().tokenize(' '.join(stopwords)),\n",
    "                                   lowercase = True)\n",
    "\n",
    "model_pip_LR = Pipeline([('countV', tfid),('Lg', LogisticRegression(random_state=4092019))])\n",
    "model_pip_LR.fit(x_train, y_train)\n",
    "\n",
    "print(classification_report(y_test,model_pip_LR.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tercer Modelo: Máquina de Soporte Vectorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "gamma = [0.0000001, 0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "parameters_first = {\n",
    "    \"kernel\":[\"rbf\"],\n",
    "    \"C\": C[:3],\n",
    "    \"gamma\": gamma[:3]\n",
    "}\n",
    "\n",
    "parameters_second = {\n",
    "    \"kernel\": [\"rbf\"],\n",
    "    \"C\": C[3:],\n",
    "    \"gamma\": gamma[3:],\n",
    "}\n",
    "\n",
    "parameters_third = {\n",
    "    \"kernel\": [\"rbf\"],\n",
    "    \"C\": C[:3],\n",
    "    \"gamma\": gamma[3:]\n",
    "}\n",
    "\n",
    "parameters_fourth = {\n",
    "    \"kernel\": [\"rbf\"],\n",
    "    \"C\": C[3:],\n",
    "    \"gamma\": gamma[:3]\n",
    "}\n",
    "\n",
    "def get_gs_svm(params):\n",
    "    return Pipeline([\n",
    "        ('countV', count_vectorizer),\n",
    "        ('grid', GridSearchCV(SVC(random_state=4092019, probability=True), param_grid=params, cv=2, n_jobs=-1, refit=True)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dado el tiempo de ejecución se separa en dos modelos\n",
    "model_GS_SVM_first = get_gs_svm(parameters_first)\n",
    "model_GS_SVM_first.fit(x_train, y_train)\n",
    "print(classification_report(y_test, model_GS_SVM_first.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segundo modelo de SVM con segundo grupo de hiperparámetros\n",
    "model_GS_SVM_second = get_gs_svm(parameters_second)\n",
    "model_GS_SVM_second.fit(x_train, y_train)\n",
    "print(classification_report(y_test, model_GS_SVM_second.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tercer modelo de SVM con tercer grupo de hiperparámetros\n",
    "model_SVC_third = get_gs_svm(parameters_third)\n",
    "model_SVC_third.fit(x_train, y_train)\n",
    "print(classification_report(y_test, model_SVC_third.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuarto modelo de SVM con tercer grupo de hiperparámetros\n",
    "model_SVC_fourth = get_gs_svm(parameters_fourth)\n",
    "model_SVC_fourth.fit(x_train, y_train)\n",
    "print(classification_report(y_test,model_SVC_fourth.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cuarto Modelo: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"n_estimators\": list(np.linspace(20, 1000, 50, dtype = \"int\")),\n",
    "    \"max_features\": [None, \"log2\", \"sqrt\"]\n",
    "}\n",
    "\n",
    "rfc = RandomForestClassifier(\n",
    "    oob_score = True,\n",
    "    criterion = \"gini\",\n",
    "    max_depth = 16,\n",
    "    random_state = 4092019\n",
    ")\n",
    "\n",
    "model_GS_rf = Pipeline([('countV', count_vectorizer),\n",
    "                         ('grid', GridSearchCV(rfc, param_grid = parameters, cv = 2, n_jobs=-1))])\n",
    "\n",
    "model_GS_rf.fit(x_train, y_train)\n",
    "\n",
    "print(classification_report(y_test, model_GS_rf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quinto Modelo: Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'alpha': [1e-3, 1e-2, 1e-1, 1],\n",
    "    'normalize': [True, False],\n",
    "}\n",
    "\n",
    "model_GS_ridge = Pipeline([\n",
    "    ('countV', count_vectorizer),\n",
    "    ('grid', GridSearchCV(RidgeClassifier(random_state=4092019), param_grid=parameters, cv = 2, n_jobs=-1))\n",
    "])\n",
    "\n",
    "model_GS_ridge.fit(x_train, y_train)\n",
    "print(classification_report(y_test, model_GS_ridge.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elección de modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para tener más información sobre cual modelo elegir, calcularemos el AUC score y además las curvas ROC de cada modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_curves = {}\n",
    "\n",
    "models = [\n",
    "    ('bernoulli', model_pip_bernoulli),\n",
    "    ('LR', model_pip_LR),\n",
    "    ('SVM', model_GS_SVM_second),\n",
    "    ('RF', model_GS_rf),\n",
    "    ('Ridge', model_GS_ridge),\n",
    "]\n",
    "\n",
    "for i, (name, model) in enumerate(models):\n",
    "    if name == 'Ridge': # https://stackoverflow.com/a/22587041\n",
    "        d = model.decision_function(x_test)\n",
    "        prob = np.exp(d) / np.sum(np.exp(d))\n",
    "    else:\n",
    "        prob = model.predict_proba(x_test)[:, 1]\n",
    "    roc_curves[i] = roc_curve(y_test, prob)\n",
    "    print(name, 'AUC:', roc_auc_score(y_test, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.title('Curva ROC')\n",
    "\n",
    "\n",
    "for i, (name, model) in enumerate(models):\n",
    "    plt.plot(roc_curves[i][0], roc_curves[i][1], lw=1, label=name)\n",
    "\n",
    "plt.plot([0, 1], ls=\"--\", lw=1)\n",
    "plt.ylabel('Verdaderos Positivos')\n",
    "plt.legend(prop={'size': 15})\n",
    "plt.xlabel('Falsos Positivos');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los puntajes AUC son parecidos, siendo el mayor el modelo de regresión.\n",
    "\n",
    "Los modelos más estables en base a las métricas de `presicion`, `recall` y `f1-score` son LR y Ridge (estos tienen todas las métricas sobre 0.7). Debido a esto sumado a que LR tiene mejor AUC, nos quedaremos con el modelo de regresión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model_pip_LR, open(\"grupo_nicos_&_tuskas_model_pip_LR.sav\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PD:\n",
    "\n",
    "¿Y qué ocurre con el Tweet de la imagen al comienzo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = \"Democrat Congresswoman totally fabricated what I said to the wife of a soldier who died in action (and I have proof). Sad!\"\n",
    "\n",
    "for i, (name, model) in enumerate(models):\n",
    "    prediction = model.predict([tweet])[0]\n",
    "    if prediction == 1:\n",
    "        print(name, ':', '👍')\n",
    "    else:\n",
    "        print(name, ':', '😡')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tal y como era de esperar 😇"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
